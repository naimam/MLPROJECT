{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import hmean\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import numbers\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "missingdata1 = pd.read_csv('input/MissingData1.txt', sep='\\s+', header=None, na_values='1.00000000000000e+99')\n",
    "missingdata2 = pd.read_csv('input/MissingData2.txt', sep='\\s+', header=None, na_values='1.00000000000000e+99')\n",
    "missingdata3 = pd.read_csv('input/MissingData3.txt', sep='\\s+', header=None, na_values='1.00000000000000e+99')\n",
    "missing_data = [missingdata1, missingdata2, missingdata3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the data:\n",
      "MISSING DATA  1: 118\n",
      "MISSING DATA  2: 3762\n",
      "MISSING DATA  3: 17752\n"
     ]
    }
   ],
   "source": [
    "# Counting the missing values\n",
    "def count_na(data):\n",
    "    print(\"Missing values in the data:\")\n",
    "    for i in range(len(data)):\n",
    "        missing_val_count = data[i].isnull().sum().sum()\n",
    "        print( \"MISSING DATA  \" + str(i+1) + \": \" + str(missing_val_count))\n",
    "        # for j in range(data[i].shape[1]):\n",
    "        #     missing_val_count = data[i].iloc[:,j].isnull().sum()\n",
    "        #     perc = (missing_val_count/data[i].shape[0])*100\n",
    "        #     perc = round(perc, 2)\n",
    "        #     print( \"\\tCOLUMN \" + str(j+1) + \": \" + str(missing_val_count) + \" (\" + str(perc) + \"%)\")\n",
    "            \n",
    "\n",
    "count_na(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. choose missing val to fill\n",
    "2. select the other vals in that row\n",
    "3. choose the number of neighbours: k = n/2\n",
    "4. calc euclidean distance from all the other rows\n",
    "5. select k nearest neighbours\n",
    "6. find the mean of the k nearest neighbours values in the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_imputation(data,n_neighbors = 2):\n",
    "    count = 0\n",
    "    ## Where are the null values in the data set\n",
    "    indexes_nan = np.argwhere(np.isnan(data))\n",
    "    n_col = data.shape[1]\n",
    "    n_row = data.shape[0]\n",
    "    final_data = data.copy()\n",
    "    for index in indexes_nan:\n",
    "        count = count + 1 \n",
    "        distances = []\n",
    "        row = index[0]\n",
    "        col = index[1]\n",
    "        x = data[row]\n",
    "        for i in range(n_row):\n",
    "            if(i==row):\n",
    "                continue\n",
    "            dist = nan_euclidean_distances(x.reshape(1,-1),data[i].reshape(1,-1))[0][0]\n",
    "            ## or u can also use the above distance function, both produce same answer\n",
    "            ## dist = nan_distance(x,data[i])\n",
    "            distances.append([dist, data[i][col]])\n",
    "        ## key=lambda x: x[0]  here x:x[0] signifies that we will sort this list using \n",
    "        ## 1st(in python indexing starts from 0) column i.e. distance\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "         ## Considering k closest points\n",
    "        distances = np.array(distances)\n",
    "        neighbors = []\n",
    "        for i in range(len(distances)):\n",
    "            if(np.isnan(distances[i,1])):\n",
    "                continue\n",
    "            neighbors.append(distances[i,1])\n",
    "            if(len(neighbors)==n_neighbors):  \n",
    "                break\n",
    "        ## replacing the nan with the mean of the closest points\n",
    "        adjusted_value = np.mean(neighbors)\n",
    "        final_data[row][col] = adjusted_value\n",
    "    \n",
    "    return(final_data)\n",
    "def optimized(data,n_neighbors = 2):\n",
    "    count = 0\n",
    "    ## Where are the null values in the data set\n",
    "    indexes_nan = np.argwhere(np.isnan(data))\n",
    "    final_data = data.copy()\n",
    "    ## it will produce a distance matrix with row in the dataset\n",
    "    dist = nan_euclidean_distances(data)\n",
    "    for index in indexes_nan:\n",
    "        count = count + 1 \n",
    "        row = index[0]\n",
    "        col = index[1]\n",
    "        ## Sorting the distance matrix for the particular row and getting top n values\n",
    "        sort_indxs = dist[row].argsort()\n",
    "        close_val = []\n",
    "        for i in sort_indxs:\n",
    "            if(np.isnan(data[i,col])):\n",
    "                continue\n",
    "            close_val.append(data[i,col])\n",
    "            if(len(close_val)==n_neighbors):\n",
    "                break\n",
    "        adjusted_value = np.mean(close_val)\n",
    "        final_data[row][col] = adjusted_value\n",
    "    return(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/MissingData1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-0a013e14d5eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_imputation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m242\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output/MissingData'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/MissingData1.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# for eaching missing value, perform knn impute and write to file\n",
    "for i in range(len(missing_data)):\n",
    "    final = knn_imputation(missing_data[i].values,n_neighbors =  242/2)\n",
    "    final = pd.DataFrame(final)\n",
    "    final.to_csv('output/MissingData'+str(i+1)+'.txt', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea458d1793ed83c4a9a1c9829b22cc5321347abf427211848a85b4a95e9b09b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
